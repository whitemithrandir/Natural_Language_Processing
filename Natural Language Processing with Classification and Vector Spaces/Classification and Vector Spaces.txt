Vocabulary & Feature Extraction
Merhaba. Tekrar hoşgeldiniz. Bu videoda, bir metni vektör olarak nasıl temsil edeceğinizi öğreneceksiniz. Bunu yapabilmeniz için önce bir kelime dağarcığı oluşturmanız gerekir ve bu, herhangi bir metni veya herhangi bir tweet'i bir sayı dizisi olarak kodlamanıza olanak tanır. O halde derinlere inelim ve bunu nasıl yapabileceğinizi görelim. Bir tweet listesi hayal edin, görsel olarak bu şekilde görünecektir. O zaman kelime bilginiz V, tweet listenizdeki benzersiz kelimelerin listesi olacaktır. Bu listeyi elde etmek için, tüm tweet'lerinizdeki tüm kelimeleri gözden geçirmeniz ve aramanızda görünen her yeni kelimeyi kaydetmeniz gerekir. Yani bu örnekte, önce ben, sonra ben ve mutluyum, çünkü vb. Ancak, ben kelimesinin ve ben kelimesinin sözlükte tekrarlanmayacağını unutmayın. Bu tweet'leri alalım ve kelime dağarcığınızı kullanarak özellikleri çıkaralım. Bunu yapmak için, kelime dağarcığınızdaki her kelimenin tweet'te görünüp görünmediğini kontrol etmeniz gerekir. I kelimesinde olduğu gibiyse, o özelliğe 1 değeri atarsınız, bunun gibi. Görünmezse, bunun gibi bir 0 değeri atarsınız. Bu örnekte, tweet'inizin temsilinde altı bir ve çok sayıda sıfır olacaktır. Bunlar, kelime dağarcığınızdaki tweet'te olmayan her benzersiz kelimeye karşılık gelir. Şimdi, az sayıda sıfır olmayan değerlere sahip bu tür gösterime seyrek gösterim denir. Şimdi bu tweetlerin bu temsiline daha yakından bakalım. Son slaytlarda, tweet'i bir kelime dağarcığına dayalı olarak temsil edecek özellikleri ayıklayarak size yol gösterdim ve bu vektöre ulaştım. Bu temsil, tüm kelime dağarcığınızın boyutuna eşit sayıda özelliğe sahip olacaktır. Bu, her tweet için 0'a eşit birçok özelliğe sahip olacaktır. Seyrek gösterimle, bir lojistik regresyon modelinin n artı 1 parametreyi öğrenmesi gerekir; burada n, kelime dağarcığınızın boyutuna eşittir ve büyük kelime dağarcığı boyutları için bunun sorunlu olacağını hayal edebilirsiniz. Modelinizi eğitmek çok fazla zaman alır ve tahminlerde bulunmak için gerekenden çok daha fazla zaman alır. Bir metin verildiğinde, bu metni V boyutunda bir vektör olarak nasıl temsil edeceğinizi öğrendiniz. Bunu özellikle bir tweet için yaptınız ve V boyutunda bir kelime dağarcığı oluşturabildiniz. problemler. Bir sonraki videoda, bu sorunları tanımlamayı öğreneceksiniz.
GÖRSEL COURSE1

Negative and Positive Frequencies
Şimdi, lojistik regresyon sınıflandırıcınızda özellikler olarak kullanabileceğiniz sayımları oluşturmayı öğreneceğiz. Spesifik olarak, bir kelime verildiğinde, kaç kez takip etmek istediğinizi, o kelimenin pozitif sınıf olarak göründüğü yer burasıdır. Başka bir kelime verildiğinde, o kelimenin negatif sınıfta kaç kez göründüğünü takip etmek istersiniz. Bu iki sayımı kullanarak, özellikleri çıkarabilir ve bu özellikleri lojistik regresyon sınıflandırıcınızda kullanabilirsiniz. Öyleyse bunu nasıl yapabileceğinize bir göz atalım. Öncelikle bu iki sınıfın nasıl görüneceğini hayal etmek faydalı olacaktır. Örneğin burada dört tweet'ten oluşan bir külliyatınız olabilir. Bu külliyatla ilişkili olarak, bir dizi benzersiz kelimeye, kelime dağarcığınıza sahip olacaksınız. Bu örnekte, kelime dağarcığınızda sekiz benzersiz kelime olacaktır. Duygu analizinin bu özel örneği için iki sınıfınız var. Bir sınıf olumlu duygularla, diğeri ise olumsuz duygularla ilişkilendirildi. Yani külliyatınızı alırsanız, pozitif sınıfa ait iki tweet'lik bir setiniz ve negatif sınıfa ait iki tweet'lik setiniz olur. Pozitif tweet setlerini ele alalım. Şimdi kelime dağarcığınıza bir göz atın. Kelime dağarcığınızdaki herhangi bir kelimenin pozitif frekansını elde etmek için, pozitif tweet'lerde göründüğü şekliyle zamanları saymanız gerekecek. Örneğin, ilk olumlu tweet'te bir kez, ikinci olumlu tweet'te başka bir kez mutlu kelimesi geçiyor. Yani pozitif frekansı ikidir. Tam tablo böyle görünüyor. Bir duraklama yapmaktan ve girişlerinden herhangi birini kontrol etmekten çekinmeyin. Aynı mantık negatif frekansı elde etmek için de geçerlidir. Bununla birlikte, netlik adına, bir örneğe bakın, am kelimesi ilk tweet'te iki kez ve ikinci tweet'te bir kez daha geçiyor. Yani negatif frekansı üçtür. Negatif frekanslar için tablonun tamamına bakın ve değerlerini kontrol etmekten çekinmeyin.
Yani bu, külliyatınız için pozitif ve negatif frekansları içeren tablonun tamamı. Uygulamada kodlama yapılırken bu tablo, oradaki bir kelime sınıfından frekansına kadar bir sözlük eşlemesidir. Böylece, kelimeyi ve karşılık gelen sınıfını, sınıfta göründüğü sıklık veya sayı ile eşler. Artık bir kelimeyi ve sınıfı o kelimenin karşılık gelen sınıfta kaç defa göründüğüne göre haritalayan bir frekans sözlüğünü nasıl oluşturacağınızı biliyorsunuz. Bir sonraki videoda, bir tweet'i temsil etmek için frekans sözlüğünüzü kullanacaksınız.

Feature Extraction with Frequencies
Tekrar hoşgeldiniz. Daha önce bir tweet'i V boyutunun bir vektörü olarak kodlamayı öğrendiniz. Şimdi bir tweet'i kodlamayı veya özellikle 3. boyutun bir vektörü olarak temsil etmeyi öğreneceksiniz. Bunu yaparken, lojistik regresyon sınıflandırıcınız için çok daha yüksek bir hıza sahip olacaksınız, çünkü V özelliklerini öğrenmek yerine sadece üç özelliği öğrenmeniz gerekiyor. Bunu nasıl yapabileceğinize bir göz atalım. Az önce bir sınıftaki bir kelimenin sıklığının, kelimenin o sınıfa ait tweet setinde görünme sayısı olduğunu ve bu tablonun temel olarak kelime sınıfı çiftlerinden frekanslara bir sözlük eşlemesi olduğunu gördünüz. sadece bize her kelimenin karşılık gelen sınıfta kaç kez göründüğünü söyler. Frekanslar sözlüğünüzü oluşturduğunuza göre, onu duyarlılık analizi için yararlı özellikler çıkarmak için kullanabilirsiniz. Bir özellik neye benziyor? Gelelim keyfi tweet m'ye. İlk özellik, 1'e eşit bir önyargı birimi olacaktır. İkincisi, tweet m'deki her benzersiz kelime için pozitif frekansların toplamıdır. Üçüncüsü, tweet'teki her benzersiz kelime için negatif frekansların toplamıdır. Dolayısıyla, bu temsilin özelliklerini çıkarmak için, yalnızca kelimelerin sıklıklarını toplamanız gerekir. Kolay. Örneğin, aşağıdaki tweet'leri alın. Şimdi son dersteki pozitif sınıfın frekanslarına bakalım. Sözlükte bu tweetlerde yer almayan tek kelime mutlu ve çünkü. Şimdi son slaytta gördüğünüz temsilden ikinci özelliğe bir göz atalım. Bu değeri elde etmek için, tweet'te görünen kelimelerin frekanslarını toplamanız gerekir. Sonunda, sekize eşit bir değer elde edersiniz. Şimdi üçüncü özelliğin değerini bulalım. Tweet'te görünen kelime dağarcığından kelimelerin negatif frekanslarının toplamıdır. Bu örnek için, altı çizili frekansları topladıktan sonra 11 elde etmelisiniz. Şimdiye kadar, bu tweet'ler, bu gösterim 1, 8, 11 vektörüne eşit olacaktır. Artık bir tweet'i 3 boyutlu bir vektör olarak nasıl temsil edeceğinizi biliyorsunuz. Bir sonraki videoda tweet'lerinizi önceden işlemeyi ve sonuç olarak, önceden işlenmiş bu kelimeleri kelime haznenizin kelimeleri olarak kullanacaksınız.

Preprocessing
Merhaba, şimdi ön işlemenin iki ana kavramını öğreneceksiniz. Öğreneceğiniz ilk şey köklendirme ve öğreneceğiniz ikinci şey ise durdurma sözcükleridir ve özellikle metinlerinizi önceden işlemek için kök ve durdurma sözcüklerini nasıl kullanacağınızı öğreneceksiniz. Bunu nasıl yapabileceğinize bir göz atalım. Bu tweet'i işleyelim. İlk olarak, tweet'lere anlamlı bir anlam katmayan tüm kelimeleri, diğer bir deyişle durdurma sözcükleri ve noktalama işaretlerini kaldırıyorum. Uygulamada, tweet'inizi iki listeyle karşılaştırmanız gerekir. Biri İngilizce durma sözcükleri ve diğeri noktalama işaretleri ile. Bu listeler genellikle çok daha geniştir, ancak bu örneğin amacı doğrultusunda gayet iyi iş görecektir. Durdurma kelimeleri listesinde de görünen tweet'teki her kelime elenmelidir. Bu yüzden, ve, are kelimesini, a kelimesini ve at kelimesini ortadan kaldırmanız gerekir. Durdurma sözleri olmayan tweet böyle görünüyor. Cümlenin genel anlamının herhangi bir çaba sarf edilmeden çıkarılabileceğine dikkat edin. Şimdi, her noktalama işaretini ortadan kaldıralım. Bu örnekte sadece ünlem işaretleri var. Durdurma sözcükleri ve noktalama işaretleri olmayan tweet böyle görünüyor. Ancak, bazı bağlamlarda noktalama işaretlerini kaldırmanız gerekmeyeceğini unutmayın. Bu nedenle, noktalama işaretlerinin sizin özel NLP görevinize önemli bilgiler ekleyip eklemediğini dikkatlice düşünmelisiniz. Tweetler ve diğer metin türleri genellikle tutamaçlara ve URL'lere sahiptir, ancak bunlar, duyarlılık analizi görevi için herhangi bir değer katmaz. Bu iki tanıtıcıyı ve bu URL'yi ortadan kaldıralım. Bu sürecin sonunda ortaya çıkan tweet'ler, duygularıyla ilgili tüm önemli bilgileri içerir. GREAT AI modelini ayarlamak açıkça olumlu bir tweet'tir ve yeterince iyi bir model bunu sınıflandırabilmelidir. Artık örnekteki tweet sadece gerekli bilgileri içerdiğine göre, her kelime için köklendirme yapacağım. NLP'de kök oluşturma, herhangi bir sözcüğü, sözcüğü ve türevlerini oluşturmak için kullanılan karakter kümesi olarak tanımlayabileceğiniz temel köküne dönüştürmektir. İlk kelimeyi örnekten alalım. Kökü yapılır, çünkü e harfini ekleyerek melodi kelimesini oluşturur. Ed ekinin eklenmesi akort kelimesini, ing ekinin eklenmesi ise akort kelimesini oluşturur. Korpusunuzda gövdeleme işlemini gerçekleştirdikten sonra, akort, akort ve akort sözcükleri kök tun'a indirgenecektir. Yani bu işlemi külliyattaki her kelime için yaptığınızda kelime bilginiz önemli ölçüde azalır. Değerli bilgileri kaybetmeden kelime dağarcığınızı daha da azaltmak için, kelimelerinizin her birini küçük harfle yazmanız gerekir. Böylece BÜYÜK, Harika ve harika sözcükleri tam olarak aynı sözcük olarak ele alınır. Bu, bir kelime listesi olarak son ön işleme tweet'idir. Artık sözcükleri köklendirmeye ve durdurmaya aşina olduğunuza göre, metin işlemenin temellerini biliyorsunuz. Bir sonraki videoda, veri kümenizdeki tüm tweet'leri temsil eden bir x matrisi çıkarmak için işlem paketi işlevinizi kullanabilirsiniz.

Putting it All Together
Şimdi, eğitim örneğinizin tüm özelliklerine karşılık gelen bir matris oluşturmak için öğrendiğiniz her şeyi kullanacaksınız. Spesifik olarak, bu x matrisini oluşturmanıza izin veren bir algoritma üzerinde size yol göstereceğim. Nasıl kurabileceğinize bir göz atalım. Daha önce, NLP'deki duygu analizi görevleri için ilgili tüm bilgileri içeren kelimelerin bir listesini almak için bunun gibi bir tweet'i nasıl önceden işleyeceğinizi gördünüz. Bu kelime listesiyle, bir frekans sözlüğü eşlemesi kullanarak güzel bir temsil elde edebilirsiniz. Ve son olarak, süreç tweet'lerinizdeki her kelimenin pozitif tweet'lerde kaç kez ve negatif tweet'lerde kaç kez göründüğünün toplamını depolayan önyargı birimi ve iki ek özelliği olan bir vektör elde edin. Uygulamada, bu işlemi bir dizi m tweet üzerinde gerçekleştirmeniz gerekir. Bu nedenle, bir dizi birden fazla ham tweet verildiğinde, her bir tweet'iniz için bu kelime listelerini elde etmek için bunları birer birer önceden işlemeniz gerekir. Ve son olarak, bir frekans sözlüğü eşlemesi kullanarak özellikleri çıkarabileceksiniz. Sonunda, her satırın tweet'lerinizin her biri için özellikleri içerdiği m satırlı ve üç sütunlu bir X matrisiniz olur. Bu sürecin genel uygulaması oldukça kolaydır. İlk olarak, frekanslar sözlüğünü oluşturursunuz, ardından X matrisini tweet sayınıza uyacak şekilde başlatırsınız. Bundan sonra, durma kelimelerini, köklerini, URL'lerini ve tanıtıcıları ve alt harfleri silerek tweet setlerinizi dikkatlice gözden geçirmek isteyeceksiniz. Ve son olarak, tweetlerin pozitif ve negatif frekanslarını toplayarak özellikleri çıkarın. Bu haftanın ödevi için size bazı yardımcı işlevler, build_freqs ve process_tweet sağlandı. Ancak, tek bir tweet'in özelliklerini çıkarmak için işlevi uygulamanız gerekecek. Bu çok fazla koddu, ama en azından artık X matrisiniz var. Bir sonraki videoda, size bu X matrisini lojistik regresyon sınıflandırıcınıza nasıl besleyebileceğinizi göstereceğiz. Bunu nasıl yapabileceğinize bir göz atalım.

Logistic Regression Overview
Artık lojistik regresyona genel bir bakış elde edeceksiniz. Önceden, özellikleri çıkarmayı öğrendiniz ve şimdi bu çıkarılan özellikleri bir tweet'in olumlu mu yoksa olumsuz mu olduğunu tahmin etmek için kullanacaksınız. Lojistik regresyon, sıfır ile bir arasında bir olasılık veren bir sigmoid işlevinden yararlanır. Lojistik regresyonun genel görünümüne bir göz atalım. Sadece hızlı bir özet. Denetimli makine öğreniminde, giriş özelliklerine ve bir dizi etikete sahipsiniz. Verilerinize dayalı tahminler yapmak için, özelliklerinizi çıktı etiketleri ile eşlemek için bazı parametrelere sahip bir işlev kullanırsınız. Özelliklerinizden etiketlere optimum bir eşleme elde etmek için, çıktınızın Y şapkasının verilerinizdeki gerçek Y etiketlerine ne kadar yakın olduğunu karşılaştırarak çalışan maliyet işlevini en aza indirirsiniz. Bundan sonra parametreler güncellenir ve maliyetiniz en aza indirilene kadar işlemi tekrarlarsınız. Lojistik regresyon için bu F fonksiyonu sigmoid fonksiyonuna eşittir. Lojistik regresyon H'de sınıflandırmak için kullanılan işlev sigmoid işlevidir ve Theta parametrelerine ve ardından i'nin i'inci gözlem veya veri noktalarını belirtmek için kullanıldığı özellik vektörü X üst simgeleri i'ye bağlıdır. Tweet'ler bağlamında, bu i'inci tweet'ler. Görsel olarak, sigmoid fonksiyonu bu forma sahiptir ve buradaki Theta devrik X'in iç çarpımı olarak sıfıra, eksi sonsuza ve bire sonsuza yaklaşırken yaklaşır. Sınıflandırma için bir eşik gereklidir. Genellikle 0.5 olarak ayarlanır ve bu değer Theta devrik ile X arasında sıfıra eşit bir iç çarpıma karşılık gelir. Dolayısıyla, iç çarpım sıfırdan büyük veya eşit olduğunda, tahmin pozitiftir ve iç çarpım sıfırdan küçük olduğunda, tahmin negatiftir. O halde, artık tanıdık olan tweet'ler ve duygu analizi bağlamında bir örneğe bakalım. Aşağıdaki tweet'e bakın. Bir ön işlemeden sonra, bunun gibi bir listeye sahip olmalısınız. Tutamaçların silindiğini, her şeyin küçük harfle yazıldığını ve akort kelimesinin kökü olan tun'a indirgendiğini unutmayın. Ardından, bir frekans sözlüğü verilen özellikleri çıkarabilir ve aşağıdakine benzer bir vektöre ulaşabilirsiniz. Buradaki bias birimleri ve işlenmiş tweet'lerinizdeki tüm kelimelerin pozitif ve negatif frekanslarının toplamı olan iki özellik. Şimdi, zaten bir optimum Theta parametre setine sahip olduğunuzu varsayarak, bu durumda 4,92'ye eşit olan sigmoid fonksiyonunun değerini elde edebilir ve son olarak pozitif bir duygu tahmin edebilirsiniz. Artık lojistik regresyon gösterimini bildiğinize göre, bunu bir ağırlık faktörü Theta'yı eğitmek için kullanabilirsiniz. Bir sonraki videoda, böyle bir lojistik regresyon sınıflandırıcıyı eğitmenin ardındaki mekanikleri öğreneceksiniz.

Logistic Regression: Training
Bir önceki videoda, size verdiğim bir teta kullanarak bir tweet'in olumlu ya da olumsuz bir duyguya sahip olup olmadığını nasıl sınıflandıracağınızı öğrendiniz. Bu videoda, kendi tetanızı sıfırdan öğreneceksiniz ve özellikle teta değişkeninizi elde etmenizi sağlayan bir algoritma üzerinde size yol göstereceğim. Bunu nasıl yapabileceğinizi görelim. Lojistik regresyon sınıflandırıcınızı eğitmek için, maliyet fonksiyonunuzu en aza indiren teta parametre kümesini bulana kadar yineleyin. Kaybınızın yalnızca theta1 ve theta2 parametrelerine bağlı olduğunu varsayalım, soldaki bu kontur çizimlerine benzeyen bir maliyet fonksiyonunuz olur. Sağ tarafta, siz tekrar ettikçe maliyet fonksiyonunun gelişimini görebilirsiniz. İlk olarak, parametrelerinizi teta başlatmanız gerekir. Daha sonra tetanızı maliyet fonksiyonunuzun gradyanına göre güncelleyeceksiniz. 100 yinelemeden sonra, bu noktada, 200 yinelemeden sonra, vb. Pek çok yinelemeden sonra, optimum maliyetlerinize yakın bir noktaya ulaşırsınız ve eğitiminizi burada bitirirsiniz. Bu sürece daha ayrıntılı olarak bakalım. Öncelikle, vektör teta parametrelerinizi başlatmanız gerekir. Ardından, gözlemlerinizin her biri için değer elde etmek için lojistik işlevi kullanırsınız. Bundan sonra, maliyet fonksiyonunuzun gradyanlarını hesaplayabilir ve parametrelerinizi güncelleyebilirsiniz. Son olarak, maliyetinizi J hesaplayabilir ve bir durdurma parametresine veya maksimum yineleme sayısına göre daha fazla yineleme gerekip gerekmediğini belirleyebilirsiniz. Diğer kurslarda görmüş olabileceğiniz gibi, bu algoritma gradyan iniş olarak bilinir. Artık teta değişkeniniz olduğuna göre, tetanızı değerlendirmek istiyorsunuz, yani sınıflandırıcınızı değerlendirmek istiyorsunuz. Tetanızı sigmoid fonksiyonunuza koyduğunuzda, iyi bir sınıflandırıcı mı yoksa kötü bir sınıflandırıcı mı elde edersiniz? Bir sonraki videoda size bunu nasıl yapabileceğinizi göstereceğiz.

Logistic Regression: Testing
Artık verileriniz olduğuna göre, bu verileri yeni veri noktalarımızı tahmin etmek için kullanacaksınız. Örneğin yeni bir tweet verildiğinde, bu tweet'in olumlu mu olumsuz mu olduğunu söylemek için bu verileri kullanacaksınız. Bunu yaparken, modelinizin iyi genelleme yapıp yapmadığını analiz etmek istersiniz. Bu videoda size modelinizin genelleme yapıp yapmadığını göstereceğiz ve özellikle modelinizin doğruluğunu nasıl hesaplayacağınızı göstereceğiz. Bunu nasıl yapabileceğinize bir göz atalım. Bunun için X_val ve Y_val'e ihtiyacınız olacak. Doğrulama kümeleri olarak da bilinen eğitimler sırasında bir kenara ayrılan veriler ve verileriniz üzerinde eğitimden elde ettiğiniz optimum parametre kümeleri olan Theta. İlk olarak, Theta parametreleriyle X_val için sigmoid işlevini hesaplayacaksınız, ardından Theta'nın her bir h değerinin, genellikle 0,5 olarak ayarlanan bir eşik değerinden büyük veya ona eşit olup olmadığını değerlendireceksiniz. Örneğin, h X Theta'nız aşağıdaki vektöre, 0,3, 0,8, 0,5, vb., doğrulama kümenizdeki örnek sayısına eşitse, bileşenlerinin her birinin veya 0.5'e eşittir. Yani 0.3, 0.5'ten büyük mü eşit mi? Hayır. Yani ilk tahminimiz 0'a eşit. 0.8, 0.5'ten büyük mü eşit mi? Evet. Yani ikinci örnek için tahminimiz 1. 0,5 0,5'ten büyük mü eşit mi? Evet. Yani üçüncü tahminimiz 1'e eşittir, vb. Sonunda, sırasıyla öngörülen negatif ve pozitif örnekleri gösteren sıfırlar ve birlerle doldurulmuş bir vektörünüz olacak. Tahmin vektörünü oluşturduktan sonra, doğrulama kümeleri üzerinden modelinizin doğruluğunu hesaplayabilirsiniz. Bunu yapmak için, yaptığınız tahminleri doğrulama verilerinizdeki her gözlem için gerçek değerle karşılaştıracaksınız. Değerler eşitse ve tahmininiz doğruysa, aksi takdirde 1 ve 0 değerini alırsınız. Örneğin, tahmininiz doğruysa, tahmininizin ve etiketinizin her ikisinin de 0'a eşit olduğu bu durumda olduğu gibi, vektörünüz ilk konumda 1'e eşit bir değere sahip olacaktır. Tersine, ikinci tahmininiz doğru değilse, tahmininiz ve etiketiniz aynı fikirde olmadığı için, vektörünüzün ikinci konumda 0 değeri olacaktır ve bu böyle devam eder. Doğrulama kümenizin gerçek etiketleriyle her tahminin değerlerini karşılaştırdıktan sonra, karşılaştırma vektörünü toplayarak tahminlerinizin doğru olduğu toplam süreleri elde edebilirsiniz. Son olarak, bu sayıyı doğrulama setlerinizdeki toplam m gözlem sayısına böleceksiniz. Bu ölçüm, lojistik regresyonunuzun görünmeyen veriler üzerinde doğru şekilde çalışacağı zamanların bir tahminini verir. Dolayısıyla, doğruluğunuz 0,5'e eşitse, bu, modelinizin zamanın yüzde 50'sinde iyi çalışmasının beklendiği anlamına gelir. Örneğin, beş gözlem için Y_val ve tahmin vektörleriniz böyle görünüyorsa, her birinin değerini karşılaştıracak ve eşleşip eşleşmediklerini belirleyeceksiniz. Bundan sonra, tahminin ve etiketin aynı fikirde olmadığı üçüncü konumda tek bir 0 olan aşağıdaki vektöre sahip olacaksınız. Daha sonra, tahminlerinizin kaç kez doğru çıktığını toplamanız ve bu sayıyı doğrulama setlerinizdeki toplam gözlem sayısına bölmeniz gerekir. Örneğin, yüzde 80'e eşit bir doğruluk elde edersiniz. Bu uzmanlığın ilk haftasını bitirdiğiniz için tebrikler. Bu hafta birçok kavram öğrendiniz. Öğrendiğiniz ilk şey, bir metni nasıl önişleyeceğinizi öğrenmiş olmanızdır. O metinden özellikleri nasıl çıkaracağınızı öğrendiniz. Ayıklanan bu özellikleri nasıl kullanacağınızı ve bunları kullanarak bir model eğitmeyi öğrendiniz. Sonra modelinizi nasıl test edeceğinizi öğrendiniz. Bu haftanın programlama alıştırmasında, bahsettiğimiz tüm bu kavramları uygulama şansına sahip olacaksınız. Devam etmekten çekinmeyin ve programlama alıştırmasını yapın. Ayrıca, bu haftanın sonunda, lojistik regresyon için maliyet fonksiyonunun arkasındaki sezgiyi kapsayan isteğe bağlı bir video da var. Bu videoyu izlemek istemiyorsanız, saf Bayes olarak bilinen yeni bir sınıflandırma algoritması hakkında bilgi edineceğiniz gelecek haftaya gitmekten çekinmeyin.

